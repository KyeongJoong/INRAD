{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import method\r\n",
    "import data_loader\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "\r\n",
    "# Hyperparameters (fixed across all dataset)\r\n",
    "HIDDEN_DIM = 256\r\n",
    "BATCH_SIZE = 131072\r\n",
    "EPOCHS = 10000\r\n",
    "EARLYSTOPPING_PATIENCE = 30\r\n",
    "FIRST_OMEGA_0 = 3000\r\n",
    "THRESHOLD_PATIENCE = 100\r\n",
    "\r\n",
    "\r\n",
    "VERBOSE = True # if True, you can check current status of operation.\r\n",
    "EVALUATE = True # if False, you can check training or convergence time wihtout evaluation (in terms of Best F1-score)\r\n",
    "\r\n",
    "\r\n",
    "# Since size of datasets we use in our experiments exceeds the available max limit by CMT, \r\n",
    "# we can only show you the simplified implementation example on a subset (one entity among 28 entities) of SMD dataset.\r\n",
    "# In order to check clear reproducibility for the result on every dataset from our proposed method INRAD, please refer to 'README.txt' file."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# DATASET can be one of \"SMD\", \"MSL\", \"SMAP\", \"SWaT\", \"WADI\"\r\n",
    "\r\n",
    "DATASET = \"SMD\" # Before downloading all dataset by refering README.txt, choice is restriced by SMD only.\r\n",
    "\r\n",
    "# Set VARIANT to True if INRAD-c\r\n",
    "VARIANT = False\r\n",
    "\r\n",
    "# Set location of main.py as PATH (Assuming that /data folder is also included in the same directory)\r\n",
    "\r\n",
    "PATH = os.getcwd() + \"\\\\data/\\\\\"\r\n",
    "\r\n",
    "dataset = data_loader.dataset_choice(DATASET, path = PATH)\r\n",
    "inrad = method.INRAD(dataset, variant=VARIANT, evaluate= EVALUATE, verbose=VERBOSE)\r\n",
    "print(\"Dataset: {}, Variant: {}\".format(DATASET, VARIANT))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset: SMD, Variant: False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "inrad.Representation_Learning(\r\n",
    "    hidden_dim=HIDDEN_DIM,\r\n",
    "    batch_size=BATCH_SIZE,\r\n",
    "    epochs=EPOCHS,\r\n",
    "    earlystopping_patience=EARLYSTOPPING_PATIENCE,\r\n",
    "    first_omega_0=FIRST_OMEGA_0,\r\n",
    ")\r\n",
    "\r\n",
    "average_p, average_r, average_f1 = inrad.evaluation(verbose=False)\r\n",
    "\r\n",
    "# Note that if the whole data is not downloaded in the given folder, printed results may be different from the ones reported in the paper.\r\n",
    "print(\"Precision: {}, Recall {}, F1-score: {}\".format(average_p, average_r, average_f1))\r\n",
    "if VARIANT == False:\r\n",
    "    print(\"average training time per epoch over entities: \", np.mean(inrad.train_time_per_epoch))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is multi-entity dataset.\n",
      "current_process:  machine-1-1\n",
      "Start evaluation in terms of Best-f1 score\n",
      "time for best_f1 score finding:  113.171471118927\n",
      "Precision: 0.9999999962880475, Recall 0.9999999962880475, F1-score: 0.9999999962880475\n",
      "average training time per epoch over entities:  0.27065497530504184\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('fsl': conda)"
  },
  "interpreter": {
   "hash": "ed0093afbaab5e3a38124b5a58fa107641efd0b5f7403fd83a5aac98f7695b22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}