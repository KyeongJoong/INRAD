{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import data_loader\r\n",
    "import modules\r\n",
    "import time\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch._C import device\r\n",
    "import utils\r\n",
    "import eval_methods\r\n",
    "\r\n",
    "device = torch.device(f\"cuda:{0}\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Customized Dataset Setting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# customized dataset structure\r\n",
    "'''\r\n",
    "You need to define x_train, x_test, y_test variable as followed with ndarray format.\r\n",
    "x_train: train data (usually without any label)\r\n",
    "x_test: test data\r\n",
    "y_test: label for test data. (1: anomaly, 0: normal)\r\n",
    "'''\r\n",
    "\r\n",
    "# We use one of the entity in SMD dataset for customized setting example.\r\n",
    "PATH = os.getcwd() + \"\\\\data/\\\\\"\r\n",
    "dataset = data_loader.dataset_choice(\"SMD\", path = PATH)\r\n",
    "data = next(iter(dataset))\r\n",
    "\r\n",
    "x_train = data.x_train\r\n",
    "x_test = data.x_test\r\n",
    "y_test = data.y_test\r\n",
    "\r\n",
    "x_dim = x_train.shape[1] # dimension of given time-series data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is multi-entity dataset.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# data shape\r\n",
    "print(\"train data shape: \", x_train.shape)\r\n",
    "print(\"test data shape: \", x_test.shape)\r\n",
    "print(\"label data shape: \", y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train data shape:  (28479, 38)\n",
      "test data shape:  (28479, 38)\n",
      "label data shape:  (28479,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Proposed Model (INRAD)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## temporal encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# If acutal timestamps are not available, you can arbitrarily make timestamps as belowed. \r\n",
    "train_timestamp = None\r\n",
    "\r\n",
    "# For the detailed understanding, please refer to the attached technical appendix pdf file.\r\n",
    "\r\n",
    "# default start: 2021-01-01 00:00:00\r\n",
    "# default interval unit : 1 minute\r\n",
    "\r\n",
    "# making timestamps for train set\r\n",
    "if train_timestamp is None:\r\n",
    "    train_timestamps = modules.timestamp_maker(\r\n",
    "        len(x_train) + 1,\r\n",
    "    )\r\n",
    "# '+1' is needed for setting start timestamp for test set  \r\n",
    "\r\n",
    "# making timestamps for test set\r\n",
    "test_timestamps = modules.timestamp_maker(\r\n",
    "                        len(x_test), start=train_timestamps[-1], unit=\"1 min\"\r\n",
    "                    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# train data timestamps\r\n",
    "print(train_timestamps[:-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 00:01:00',\n",
      "               '2021-01-01 00:02:00', '2021-01-01 00:03:00',\n",
      "               '2021-01-01 00:04:00', '2021-01-01 00:05:00',\n",
      "               '2021-01-01 00:06:00', '2021-01-01 00:07:00',\n",
      "               '2021-01-01 00:08:00', '2021-01-01 00:09:00',\n",
      "               ...\n",
      "               '2021-01-20 18:29:00', '2021-01-20 18:30:00',\n",
      "               '2021-01-20 18:31:00', '2021-01-20 18:32:00',\n",
      "               '2021-01-20 18:33:00', '2021-01-20 18:34:00',\n",
      "               '2021-01-20 18:35:00', '2021-01-20 18:36:00',\n",
      "               '2021-01-20 18:37:00', '2021-01-20 18:38:00'],\n",
      "              dtype='datetime64[ns]', length=28479, freq='T')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# test data timestamps\r\n",
    "print(test_timestamps)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatetimeIndex(['2021-01-20 18:39:00', '2021-01-20 18:40:00',\n",
      "               '2021-01-20 18:41:00', '2021-01-20 18:42:00',\n",
      "               '2021-01-20 18:43:00', '2021-01-20 18:44:00',\n",
      "               '2021-01-20 18:45:00', '2021-01-20 18:46:00',\n",
      "               '2021-01-20 18:47:00', '2021-01-20 18:48:00',\n",
      "               ...\n",
      "               '2021-02-09 13:08:00', '2021-02-09 13:09:00',\n",
      "               '2021-02-09 13:10:00', '2021-02-09 13:11:00',\n",
      "               '2021-02-09 13:12:00', '2021-02-09 13:13:00',\n",
      "               '2021-02-09 13:14:00', '2021-02-09 13:15:00',\n",
      "               '2021-02-09 13:16:00', '2021-02-09 13:17:00'],\n",
      "              dtype='datetime64[ns]', length=28479, freq='T')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# temporal encoding\r\n",
    "train_encoded_input = modules.temporal_encoding(train_timestamps[:-1])\r\n",
    "test_encoded_input = modules.temporal_encoding(test_timestamps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# encoded time (input of our method) for train set\r\n",
    "print(train_encoded_input)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -0.9661, -1.0000],\n",
      "        [-1.0000, -1.0000, -1.0000, -1.0000, -0.9322, -1.0000],\n",
      "        ...,\n",
      "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.2203, -1.0000],\n",
      "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.2542, -1.0000],\n",
      "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.2881, -1.0000]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# encoded time (input of our method) for test set\r\n",
    "print(test_encoded_input)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.0000, -1.0000,  0.2667,  0.5652,  0.3220, -1.0000],\n",
      "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.3559, -1.0000],\n",
      "        [-1.0000, -1.0000,  0.2667,  0.5652,  0.3898, -1.0000],\n",
      "        ...,\n",
      "        [-1.0000, -0.8182, -0.4667,  0.1304, -0.4915, -1.0000],\n",
      "        [-1.0000, -0.8182, -0.4667,  0.1304, -0.4576, -1.0000],\n",
      "        [-1.0000, -0.8182, -0.4667,  0.1304, -0.4237, -1.0000]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implicit Neural Representation model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Hyperparameters \r\n",
    "# We fix these across all datasets\r\n",
    "hidden_dim=256\r\n",
    "batch_size=131072 # 2^17 (full batch as long as memory capacity allows)\r\n",
    "epochs=1 # For simplicity, we set it as 1, however originally we set it as 10000\r\n",
    "earlystopping_patience=30\r\n",
    "first_omega_0=3000\r\n",
    "\r\n",
    "# Model initialization\r\n",
    "\r\n",
    "model = modules.Siren(\r\n",
    "    in_features=train_encoded_input.shape[1],\r\n",
    "    out_features=x_dim,\r\n",
    "    hidden_features=hidden_dim,\r\n",
    "    hidden_layers=3,\r\n",
    "    first_omega_0=first_omega_0,\r\n",
    "    outermost_linear=True,\r\n",
    ")\r\n",
    "model.to(device)\r\n",
    "\r\n",
    "optim = torch.optim.Adam(lr=1e-4, params=model.parameters())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Implicit Nerual Representation Learning on train set.\r\n",
    "\r\n",
    "data_train = modules.Timedata(x_train, train_encoded_input)\r\n",
    "train_dataloader = DataLoader(\r\n",
    "    data_train,\r\n",
    "    shuffle=True,\r\n",
    "    batch_size=batch_size,\r\n",
    "    pin_memory=True,\r\n",
    "    num_workers=0,\r\n",
    ")\r\n",
    "\r\n",
    "early_stopping = utils.EarlyStopping(\r\n",
    "    patience=earlystopping_patience, verbose=False\r\n",
    ")\r\n",
    "\r\n",
    "epoch_time = []\r\n",
    "for step in range(epochs):\r\n",
    "    epoch_start = time.time()\r\n",
    "    model_loss = 0\r\n",
    "    for batch_model_input, batch_ground_truth in train_dataloader:\r\n",
    "        batch_model_input = batch_model_input.to(device)\r\n",
    "        batch_ground_truth = batch_ground_truth.to(device)\r\n",
    "\r\n",
    "        batch_model_output, _ = model(batch_model_input)\r\n",
    "        loss = F.mse_loss(batch_model_output, batch_ground_truth)\r\n",
    "        optim.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optim.step()\r\n",
    "        model_loss += loss.item()\r\n",
    "        batch_model_input = batch_model_input.detach().cpu()\r\n",
    "        batch_ground_truth = batch_ground_truth.detach().cpu()\r\n",
    "    epoch_time.append(time.time() - epoch_start)\r\n",
    "    early_stopping(model_loss)\r\n",
    "    if early_stopping.early_stop:\r\n",
    "        break\r\n",
    "    \r\n",
    "print(\"average training time per epoch: \", np.mean(epoch_time))\r\n",
    "    \r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "average training time per epoch:  0.277463436126709\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Implicit Nerual Representation Learning on test set (re_training). For adopting variants of our method, INRAD-c, you can directly start this phase without using train set.\r\n",
    "\r\n",
    "data_test = modules.Timedata(x_test, test_encoded_input)\r\n",
    "test_dataloader = DataLoader(\r\n",
    "    data_test,\r\n",
    "    shuffle=True,\r\n",
    "    batch_size=batch_size,\r\n",
    "    pin_memory=True,\r\n",
    "    num_workers=0,\r\n",
    ")\r\n",
    "\r\n",
    "early_stopping = utils.EarlyStopping(\r\n",
    "    patience=earlystopping_patience, verbose=False\r\n",
    ")\r\n",
    "\r\n",
    "print(\"re-training start\")\r\n",
    "for step in range(epochs):\r\n",
    "    epoch_start = time.time()\r\n",
    "    model_loss = 0\r\n",
    "    for batch_model_input, batch_ground_truth in train_dataloader:\r\n",
    "        batch_model_input = batch_model_input.to(device)\r\n",
    "        batch_ground_truth = batch_ground_truth.to(device)\r\n",
    "        batch_model_output, _ = model(batch_model_input)\r\n",
    "        loss = F.mse_loss(batch_model_output, batch_ground_truth)\r\n",
    "        optim.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optim.step()\r\n",
    "        model_loss += loss.item()\r\n",
    "        batch_model_input = batch_model_input.detach().cpu()\r\n",
    "        batch_ground_truth = batch_ground_truth.detach().cpu()\r\n",
    "    early_stopping(model_loss)\r\n",
    "    if early_stopping.early_stop:\r\n",
    "        break\r\n",
    "print(\"re-training end\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "re-training start\n",
      "re-training end\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# anomaly score calculation\r\n",
    "total_input = data_test.timepoints\r\n",
    "model = model.cpu()\r\n",
    "total_ground_truth = data_test.data_ready\r\n",
    "total_model_output, _ = model(total_input)\r\n",
    "\r\n",
    "anomaly_score = np.mean(\r\n",
    "    np.abs(\r\n",
    "        np.squeeze(\r\n",
    "            total_ground_truth.numpy()\r\n",
    "            - total_model_output.detach().cpu().numpy()\r\n",
    "        )\r\n",
    "    ),\r\n",
    "    axis=1,\r\n",
    ")\r\n",
    "# The larger the anomaly score is, the higher possiblity of abnormal status is."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# Evaluation based on Best F1-score \r\n",
    "# Note that for simplicity, we set number of epoch as 1.\r\n",
    "\r\n",
    "accuracy, threshold = eval_methods.bf_search(anomaly_score, y_test, verbose = False)\r\n",
    "print(\"Precision: {}, Recall {}, F1-score: {}\".format(accuracy[1], accuracy[2], accuracy[0]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: 0.9262323304852383, Recall 0.9974016295567868, F1-score: 0.9604954502640649\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('fsl': conda)"
  },
  "interpreter": {
   "hash": "ed0093afbaab5e3a38124b5a58fa107641efd0b5f7403fd83a5aac98f7695b22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}